# The-AgEvent-theory
A theory to re-phrase or re-describe the Relation of an Agent to the Environment in Reinforcement-Learning(RL).

# Brief Note:
The statements below are for educational purposes only, Which defines the relationship between an Agent and Environment in Reinforcement-Learning(RL) in a more clear point-of-view. That is that how both terms are identical or non-identical to one-another based on their behviour, functionality and infrastructure.

## The need of re-description.
[You can skip this]

![alt text](https://github.com/Sikander-SD/The-AgEvent-theory/blob/images/Basic.png?raw=true)

As the image above is simple, A DNN-model takes input(data) and give output(prediction) and to be more accurate in predictions, The model weights has to be updated timely with a loss function. A loss function in normaly speaking is a function which calculates the difference between the Lable of the data and the Prediction by the model (loss = y - pred). This is quite simple when we are working on a model which is based on Supervised Machine Learning, But when it comes to Unsupervised Machine Learning, we do not have any access or approach to Labels. We only have the input Data wihout Labels.Then in that case we can not calculate the loss in the same way as we do|did in Supervised Machine Leaning.

I am working on a project that is entirely based on Unsupervised Machine|Deep Leaning and i had to find out how should i calclute the loss for my model.

![alt text](https://github.com/Sikander-SD/The-AgEvent-theory/blob/images/reinforcement%20learning%20Agent%20and%20Environment%20sturcture.png?raw=true)
![alt text](https://github.com/Sikander-SD/The-AgEvent-theory/blob/images/comparing%20RL%20architectures.png?raw=true)
![alt text](https://github.com/Sikander-SD/The-AgEvent-theory/blob/images/ditricircle.png?raw=true)
![alt text](https://github.com/Sikander-SD/The-AgEvent-theory/blob/images/chessboard.png?raw=true)
